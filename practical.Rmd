---
title: "Statistical Analysis of Biological Data"
author: "Mark Dunning"
date: "8 July 2019"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part I

## How to test for normality

We will read some example data to illustrate how one would test for a normally-distributed variable. This property is important as it influences which test we should use.


First we will load the `tidyverse` set of packages that are recommended for data manipulation and visualisation. The data for this first section are to be found in the file `normal_example.csv` in the `data` folder. You will need to specify the file path accordingly.

```{r message=FALSE}
library(tidyverse)
df1 <- read_csv("data/normal_example.csv")
```

We can inspect the data in RStudio and discover that it consists of a single column called `x` that comprises numeric observations

```{r}
View(df1)
```

Various graphical methods are available to assess the distrbution. The first of which is a *histogram*. Here, the data are split into "bins" (`ggplot2` choses the number of bins) and the value on the `y` axis corresponds to the number of observations in that bin. The user only has to specify the variable to be plotted, and `ggplot2` takes care of the binning. From this plot we can judge what the average value of the data is and the spread.

```{r}
ggplot(df1, aes(x=x)) + geom_histogram()
```

A similar option is to produce a density curve. Here the y-axis is the *density* of a particular value.

```{r}
ggplot(df1, aes(x = x)) + geom_density()
```

The third option is a the boxplot which shows the median, and quartiles of the distribution.

```{r}
ggplot(df1, aes(x="",y=x)) + geom_boxplot()
```

A *violin plot* is sometimes used in conjunction with the boxplot to show density information.

```{r}
ggplot(df1, aes(x="",y=x))  + geom_violin() + geom_boxplot()
```


Finally, we have a "*qq-plot*" which allows to compare the quantiles of our dataset against a theoretical normal distribution. If the majority of points lie on a diagonal line then the data are approximately normal.

```{r}
ggplot(df1,aes(sample=x)) + geom_qq() + geom_qq_line(col="red")
```

These graphical methods are by far the easiest way to assess if a given dataset is normally-distributed. For "real-life" data, the results are unlikely to give a perfect plot, so some degree of judgement and prior experience with the data type are required. 


In fact, these data were simulated from a normal distribution. Now lets read some more realistic data

```{r}
df2 <- read_csv("data/toy_example.csv")
df2
```
******
******
******

#### Exercise

- Are the datasets `x` and `y`, contained in the data frame `df2` normally-distributed or not? Use the plots introduced above to justify your answer.

******
******
******


## Tests for normality

There are a couple of methods for testing whether variables are normally-distributed or not.

```{r}

#shapiro test
#p<0.05 ...difference between data and normality..data not normal
#p>0.05 ...no diff between data and normality ..data normally distributed

shapiro.test(df1$x)

```

```{r}
#kolomogorov-Smirnov test
ks.test(df1$x,"pnorm", mean=mean(df1$x), sd=sd(df1$x))

#what test to choose
#kolomogorov-Smirnov test...sample >=1000
#Shapiro....smaller samples but more strict(<5000)
```





## Summary Statistics

In the [accompanying R course](http://sbc.shef.ac.uk/r-crash-course/) we have seen how to produce summary statistics of columns in a dataset. For a dataset that is normally-distributed, appropriate measures of the average and variability are the mean and standard deviation. Both these functions are available within R and can be used in conjunction with the `summarise` function in `tidyverse`.

```{r}
summarise(df1, Mean = mean(x), 
          Var= var(x),
          SD = sd(x),
          SE = sd(x) / sqrt(n()))
```

The `psych` package provides a convenient function `describe` for generating these statistics, and more

```{r}
library(psych)
describe(df2)

```


******
******
******

#### Exercise

1- Read the excel file called ‘EX Biostat P1’ into R 
2- Identify if the age and hospitalization days are normally distributed
3- Use the appropriate descriptive statistics [mean±SD or median (IQ range)] for each variable 


******
******
******

# Part 2 - Contingency tables

To demonstrate the analysis of contingency tables we will use a dataset provided with the `vcd` package. You will need to install this package using the R command

```{r eval=FALSE}
install.packages("vcd")
```


The data frame `Arthritis` should then be accessible which is described as:- 

> Data from Koch & Edwards (1988) from a double-blind clinical trial investigating a new treatment for rheumatoid arthritis.

```{r}
#let's use the'Arthritis' dataset in the 'vcd' package 
library(vcd)
Arthritis
```

<div class="alert alert-warning">

**Question: What do you think the null hypothesis for this dataset might be? How would you test it and what would your summary statistics be?**

</div>

We can use the `summarise` function to obtain counts of a single variable with the special `n()` function. Grouping using the `group_by` function determines which variables are counted.



```{r}
##one way table (count of one variable)
group_by(Arthritis, Sex) %>% 
  summarise(N = n())
```

Further manipulation of this table will give proportions (which will ultimately be used in the statistical testing)

```{r}
group_by(Arthritis, Sex) %>% 
  summarise(N = n())
```


```{r}
#to get proportion of males and females
group_by(Arthritis, Sex) %>% 
  summarise(N = n()) %>% 
  mutate(prop = prop.table(N))
```

With `group_by` we can use two variables to summarise by. The order in which they are specified will dictate how the proportions are calculated.

```{r}
group_by(Arthritis, Sex, Improved) %>% 
  summarise(N = n()) %>% 
  mutate(prop = prop.table(N))

```

```{r}
group_by(Arthritis, Improved, Sex) %>% 
  summarise(N = n()) %>% 
  mutate(prop = prop.table(N))
```

If we simply want the proportions over the whole dataset, we could divide by the total number of rows

```{r}
group_by(Arthritis, Sex, Improved) %>% 
  summarise(N = n()) %>% 
  mutate(prop = N/84)
```

The function `chisq.test` can be used to assess whether differences in proportions are significant or not. Unfortunately it requires data to be presented in a different format; that of a contingency table with rows and columns for each variable being investigated. For such a transformation we can use the `spread` function from `tidyverse` which will transform a *long* table into a *wide* one.

```{r}
group_by(Arthritis, Improved, Treatment) %>% 
  summarise(N = n()) %>% 
  spread(Improved, N)
```

The `chisq.test` function will provide a p-value that we can use to assess significance.

```{r}
group_by(Arthritis, Improved, Treatment) %>% 
  summarise(N = n()) %>% 
  spread(Improved, N) %>%
  select(-Treatment) %>% 
  chisq.test()
```

Should the assumptions of the chi-squared test not be valid, the Fishers' exact test can be used instead.

```{r}
group_by(Arthritis, Improved, Sex) %>% 
  summarise(N = n()) %>% 
  spread(Improved, N) %>%
  select(-Sex) %>% 
  fisher.test()
```

Three-way contingency tables are also possible. i.e. to see if there is an improvement in treatment depending on Sex and Treatment type. However, the `xtabs` function has to be used to construct a 3D table that can be analysed by the `mantelhaen.test` function.

```{r}
ct <- group_by(Arthritis, Improved, Sex,Treatment) %>% 
  summarise(N = n()) %>% 
  xtabs(N ~ Improved + Sex + Treatment,data=.)

mantelhaen.test(ct)
```


******
******
******

#### Exercise

******
******
******

- Read the excel file called `EX Biostat P2.xls` into R 

- Make a cross table named `GenderGrade` showing the gender in the rows and tumor grade in the columns

- Define the percentage of females with Grade III tumor in the total sample 

- Define the percentage of Grade III tumors within females only

- Add a column in the `GenderGrade` table showing the sum of the 3 grades in males and in females and state the total number of males and females in the sample 

- Use the appropriate test to check if the tumor grade depends on the gender 

- Create a multi-dimensional table containing all 3 variables together in the same table

- Use the appropriate test to check if the type of effective drug is dependent on gender and tumor grade

******
******
******

# Part 3 - Comparing 2 or more continuous variables

In this part we will show how to perform tests to compare 2 (or more) continuous variables. We will simulate some example data to be used for the examples.

```{r}
set.seed(20190717)

#make some data
season <- sample(c("spring","summer","autumn","winter"),50,TRUE)
E <- rnorm(50,5,6)
F <- rnorm(50,7.8,4.5)
G <- rnorm(50,65,16.7)

rates <- data.frame(season,E,F,G) 
# in excel the grouping variable must be 'character' not numbers
head(rates)
```

The data are presented in a table with one column for each season and a measurement of either E, F or G. Data in this form are sometimes referred to as *wide* data and are not especially convenient for analysis with `dplyr` and `ggplot2`. 

In the first stage of our analysis we would like to visualise and compare the distribution of our variables, but this is not straightforward with one line of `tidyverse` code.

It turns out that we can convert the data into *long* format for analysis. The contents of the data frame are the same, just transformed into a different shape. Arguably, these data are less convenient for humans to visualise, but allows the data to be manipulated using the tools we are familiar with.

The `tidyr` package provides a function called `gather` that will convert from wide to long data.

```{r}
tidyr::gather(rates, key=variable, value=value,-season)
```

The consequence is that the new data frame can be plotted using `ggplot` in a familiar way. With the "piping" features of `tidyverse` we actually don't have to make permanent changes to the underlying data. A boxplot of the data can be created as follows:-

```{r}
rates %>% gather(variable, value, -season) %>%
  ggplot(aes(x = variable, y = value)) + geom_boxplot() + geom_jitter(width=0.1)
```


## The Independant t test.......TWO independant groups 

Lets consider that we want to compare the rates of a particular variable (say E) between summer and winter. Here we have two groups and these can be treated as *independant* variables.


```{r}
rates1 <- rates %>% gather(variable, value, -season) %>%
  filter(season %in% c("summer","winter"),variable=="E") 
rates1
```

For such a test we need to test if the variances in the two groups are roughly the same. The easiest means of doing this is graphically.

```{r}
ggplot(rates1, aes(x = season,y=value)) + geom_boxplot()
```

We can now use the `t.test` function to perform an *independant* test. The first argument is the R formula notation for the test being performed. This function allows various type of test to be performed by changing the appropriate arguments (see the help for `t.test` for details (`?t.test`)).

```{r}
t.test(value ~ season, data=rates1 ,var.equal = FALSE)
```

The `t.test` function in R and specification of the formula means that different hypotheses can be tested on the same data.

Now lets create another data frame which contains data for variables E and F and summer and winter months.

```{r}
rates2 <- rates %>% gather(variable, value, -season) %>%
  filter(variable %in% c("E","F"), season %in% c("summer","winter"))
rates2
```


First we test if the variances of the two groups are roughly the same
```{r}
rates2 %>% group_by(variable) %>% 
  summarise(Variance=var(value))

rates2 %>% 
  ggplot(aes(x = variable,y=value)) + geom_boxplot()

```

They do not seem to be, so we should employ a test that does not assume equal variances. As it happens, this is the default option for `t.test`.

```{r}
t.test(value~variable,data=rates2)
```

## The Paired t test.......TWO dependant groups 

```{r}
t.test(value~variable,data=rates2,paired=TRUE)
```

```{r}
rates3 <- rates %>% gather(variable, value, -season) %>%
  filter(variable=="F")

pairwise.t.test(rates3$value,rates3$season)  
```

# Compare between TWO GROUPS 
# B] Non- Parametric (Wilcoxon test)

#1-Independant samples = Wilcoxon rank sum test (Mann Whitney U test)


```{r}
wilcox.test(value~season, data=rates1)
```

```{r}
wilcox.test(value~variable,data=rates2)
```

#2-Paired samples = Wilcoxon signed rank test

```{r}
wilcox.test(value~variable,data=rates2,paired=TRUE)
```

# Compare between MORE THAN TWO GROUPS 
# A] Non-Parametric (Kruskal Wallis)

#1-Independant samples = kruskal Wallis

```{r}
rates_e <- rates %>% gather(variable, value, -season) %>%
  filter(variable=="E")
rates_e

```

```{r}
kruskal.test(value ~ season, data=rates_e)
```

```{r eval=FALSE}
###CHECK#
rates %>% gather(variable, value, -season) %>%
  kruskal.test(value ~ variable, data=.)
```

# Compare between MORE THAN TWO GROUPS 
# B] Parametric (ANOVA)


```{r}
anova <- aov(value ~ season, data=rates_e)
anova
summary(anova)
```

```{r}
set.seed(5)
E <- rnorm(50,5,6)
F <- rnorm(50,7.8,4.5)
G <- c(50:99)

```

```{r}
anova <- data.frame(E,F,G) %>% gather %>% 
  aov(value ~ key, data=.)
anova
summary(anova)
```

```{r}
TukeyHSD(anova)
```

```{r}
plot(TukeyHSD(anova))
```

## Two-way ANOVA

```{r}
medulloblastoma <- readxl::read_xlsx("data/Medulloblastoma.xlsx")
```

```{r}
twoway <- aov(`C-myc` ~ Site + Size,data=medulloblastoma)
summary(twoway)
```

```{r}
ggplot(medulloblastoma,aes(x = Metastasis, y=`C-myc`)) + geom_boxplot()
```

